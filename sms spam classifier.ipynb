import pandas as pd
df = pd.read_csv('/content/drive/My Drive/ML/SPAM text message 20170820 - Data.csv')
df.head()

df.info()

x = df.iloc[:,1].values
y = df.iloc[:,0].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)
print(x_train.shape)
print(x_test.shape)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix,classification_report

text_model = Pipeline([('tfidf',TfidfVectorizer()),('model',MultinomialNB())])

text_model.fit(x_train,y_train)

y_pred = text_model.predict(x_test)
y_pred

accuracy_score(y_pred,y_test)*100

confusion_matrix(y_pred,y_test)

print(classification_report(y_pred,y_test))

from wordcloud import WordCloud, STOPWORDS 
import matplotlib.pyplot as plt

comment_words = '' 
stopwords = set(STOPWORDS) 
  
# iterate through the csv file 
for val in df['Message']:
  val = str(val) 
  tokens = val.split() 

  for i in range(len(tokens)): 
    tokens[i] = tokens[i].lower()     
  comment_words += " ".join(tokens)+" "

wordcloud = WordCloud(width = 800, height = 800, 
                      background_color ='white', 
                      stopwords = stopwords, 
                      min_font_size = 10).generate(comment_words)

plt.figure(figsize = (8, 8), facecolor = None) 
plt.imshow(wordcloud) 
plt.axis("off") 
plt.tight_layout(pad = 0) 
  
plt.show()

